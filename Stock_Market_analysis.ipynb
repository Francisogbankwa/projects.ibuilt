{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjj+NeQGH5M+s2GtxcIISg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Francisogbankwa/projects.ibuilt/blob/main/Stock_Market_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJDCM7Yo3uvI"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yfinance"
      ],
      "metadata": {
        "id": "Tep_znO147iS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "9Ajd8gNl5GYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = yf.download(\"GOOGL\", start = \"2022-01-01\", interval = '1d')"
      ],
      "metadata": {
        "id": "gl_5FVuD5I-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "Dh2cLry8547K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(3)"
      ],
      "metadata": {
        "id": "R19EHSM86KtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort the data points based on indexes just for confirmation\n",
        "data.sort_index(inplace = True)"
      ],
      "metadata": {
        "id": "CphhPfL07dNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove any duplicate index\n",
        "data = data.loc[~data.index.duplicated(keep='first')]"
      ],
      "metadata": {
        "id": "aKuq2NWp7kp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.tail(3)"
      ],
      "metadata": {
        "id": "jw0VUyhK76tT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "SnEkNz1D79SV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "id": "cwTAcwO78JrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "# Check the trend inn Closing Values\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(x = data.index , y = data['Close'], mode = 'lines'))\n",
        "fig.update_layout(height = 500, width = 900,\n",
        "                  xaxis_title= 'Date', yaxis_title='Close')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "4uPYISoy8Mtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pickle\n",
        "from tqdm.notebook import tnrange"
      ],
      "metadata": {
        "id": "MDJvfmgZABHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter only required data\n",
        "data = data[['Close','Volume']]\n",
        "data.head(3)"
      ],
      "metadata": {
        "id": "g7UpHsE9AbxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirm the Testing Set length\n",
        "test_length = data[(data.index >= '2020-09-01')].shape[0]"
      ],
      "metadata": {
        "id": "gbsUucglAnFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CreateFeatures_and_Targets(data, feature_length):\n",
        "  X = []\n",
        "  Y = []\n",
        "\n",
        "  for i in tnrange(len(data)- feature_length):\n",
        "    X.append(data.iloc[i : i + feature_length,:].values)\n",
        "    Y.append(data[\"Close\"].values[i + feature_length])\n",
        "\n",
        "  X = np.array(X)\n",
        "  Y = np.array(Y)\n",
        "\n",
        "  return X , Y\n",
        "  "
      ],
      "metadata": {
        "id": "HdtN5PnCBB60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X , Y = CreateFeatures_and_Targets(data, 32)"
      ],
      "metadata": {
        "id": "6b8MWfjo07X8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the shapes\n",
        "X.shape , Y.shape"
      ],
      "metadata": {
        "id": "s4IrBjaH1BtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain , Xtest , Ytrain , Ytest = X[:-test_length] , X[-test_length:] , Y[:-test_length] , Y[-test_length:]"
      ],
      "metadata": {
        "id": "lTmksDsU32OJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Training Dataset Shape\n",
        "Xtrain.shape, Ytrain.shape"
      ],
      "metadata": {
        "id": "ipIAYVp54gLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Training Dataset Shape\n",
        "Xtest.shape , Ytest.shape"
      ],
      "metadata": {
        "id": "Z2aGypUD5exX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Scaler to Scale Vectors with Multiple Dimensions\n",
        "class MultiDimensionScaler():\n",
        "  def __init__(self):\n",
        "    self.scalers = []\n",
        "\n",
        "  def fit_transform(self,X):\n",
        "    total_dims = X.shape[2]\n",
        "    for i in range(total_dims):\n",
        "      Scaler = MinMaxScaler()\n",
        "      X[:,:,i] = Scaler.fit_transform(X[:,:,i])\n",
        "      self.scalers.append(Scaler)\n",
        "    return X\n",
        "\n",
        "    def transform(self , X):\n",
        "      for i in range(X.shape[2]):\n",
        "        X[:,:,i] = self.scalers[i].transform(X[:,:,i])\n",
        "      return X"
      ],
      "metadata": {
        "id": "7WI6Pk7W5oI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Feature_Scaler = MultiDimensionScaler()\n",
        "Xtrain = Feature_Scaler.fit_transform(Xtrain)\n",
        "Xtest = Feature_Scaler.transform(Xtest)"
      ],
      "metadata": {
        "id": "gGb6M6pU7NZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Target_Scaler = MinMaxScaler()\n",
        "Ytrain = Target_Scaler.fit_transform(Ytrain.reshape(-1,1))\n",
        "Ytest = Target_Scaler.transform(Ytest.reshape(-1,1))"
      ],
      "metadata": {
        "id": "Gm71u5Lw7hip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_object(obj , name : str):\n",
        "  pickle_out = open(f\"{name}.pck\",\"wb\")\n",
        "  pickle.dump(obj, pickle_out)\n",
        "  pickle_out.close()\n",
        "\n",
        "def load_object(name : str):\n",
        "  pickle_in = open(f\"{name}.pck\",\"rb\")\n",
        "  data = pickle.load(pickle_in)\n",
        "  return data"
      ],
      "metadata": {
        "id": "s2MQj0JOE8Jo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint , ReduceLROnPlateau\n",
        "\n",
        "save_best = ModelCheckpoint(\"best_weights.h5\", monitor='val_loss', save_best_only=True, save_weights_only=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.25,patience=5, min_lr=0.00001,verbose = 1)"
      ],
      "metadata": {
        "id": "zFxEYGh6GIHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense , Dropout, LSTM, Bidirectional\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Bidirectional(LSTM(512 , return_sequences=True , recurrent_dropout=0.1, input_shape=(32,2))))\n",
        "model.add(LSTM(256, recurrent_dropout=0.1))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64, activation='elu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(32 , activation='elu'))\n",
        "model.add(Dense(1, activation='linear')) # Final Layer"
      ],
      "metadata": {
        "id": "Yi7GOPdLHeIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer = tf.keras.optimizers.Adam(learning_rate=0.002)\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate = 0.002)\n",
        "model.compile(loss='mse', optimizer=optimizer)"
      ],
      "metadata": {
        "id": "Bmgb2NH0JgYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(Xtrain, Ytrain,\n",
        "            epochs=10,\n",
        "            batch_size = 1,\n",
        "            verbose=1,\n",
        "            shuffle=False ,\n",
        "            validation_data=(Xtest, Ytest),\n",
        "            callbacks=[reduce_lr , save_best])"
      ],
      "metadata": {
        "id": "rUam6OzJJ5i1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best weights\n",
        "model.load_weights(\"best_weights.h5\")"
      ],
      "metadata": {
        "id": "ubJ2FmuPK5-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Predictions = model.predict(Xtest)"
      ],
      "metadata": {
        "id": "SIE1cFYDPt1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Predictions = Target_Scaler.inverse_transform(Predictions)\n",
        "Actual = Target_Scaler.inverse_transform(Ytest)"
      ],
      "metadata": {
        "id": "9JXL8QsNQMvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Predictions.shape"
      ],
      "metadata": {
        "id": "yal-uatsQcmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Predictions = np.squeeze(Predictions , axis = 1)\n",
        "Actual = np.squeeze(Actual , axis = 1)"
      ],
      "metadata": {
        "id": "JfxQMkuMQfi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the Predictions vs Actual \n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(x = data.index[-test_length:] , y = Actual , mode = 'lines', name='Actual'))\n",
        "fig.add_trace(go.Scatter(x = data.index[-test_length:] , y = Predictions , mode = 'lines', name = 'Predicted'))\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "4OTBppP5Q9FY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Total_features = np.concatenate((Xtrain , Xtest) , axis = 0)"
      ],
      "metadata": {
        "id": "DoMwsJAkS2pD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Total_Targets = np.concatenate((Ytrain , Ytest) , axis = 0)"
      ],
      "metadata": {
        "id": "hKj613_aTXzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Predictions = model.predict(Total_features)"
      ],
      "metadata": {
        "id": "ksUi0-EyTifi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Predictions = Target_Scaler.inverse_transfrom(Predictions)\n",
        "Actual = Target_Scaler.inverse_transform(Total_Targets)"
      ],
      "metadata": {
        "id": "FSmgd_8zTrtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Predictions = np.squeeze(Predictions , axis = 1)\n",
        "Actual = np.squeeze(Actual , axis = 1)"
      ],
      "metadata": {
        "id": "a7oVaDVET7tT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(x = data.index , y = Actual , mode = 'lines', name='Actual'))\n",
        "fig.add_trace(go.Scatter(x = data.index , y = Predictions , mode = 'lines', name = 'Predicted'))\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "bIa7RYIsUDgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests \n",
        "\n",
        "response = requests.get('https://www.alphavantage.co/query?function=RSI&symbol=GOOGL&interval=daily&time_period=5&series_type=close&apikey=43T9T17VCV2ME4SM') \n",
        "response = response.json()"
      ],
      "metadata": {
        "id": "kGNu6M1LUlsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response.keys()"
      ],
      "metadata": {
        "id": "5h-NULRfXBei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rsi_data = pd.DataFrame.from_dict(response['Technical Analysis: RSI'] , orient='index')"
      ],
      "metadata": {
        "id": "tbtXIM9kXJJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rsi_data.head()"
      ],
      "metadata": {
        "id": "VZnx7EIfXOKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rsi_data = rsi_data[rsi_data.index >= '2018-01-01']"
      ],
      "metadata": {
        "id": "YBvXbpWZXVzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rsi_data['RSI'] = rsi_data['RSI'].astype(np.float64)"
      ],
      "metadata": {
        "id": "W2-IHys7XdZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rsi_data.head()"
      ],
      "metadata": {
        "id": "ChLz9nBrXi1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.merge(rsi_data, left_index=True, right_index=True, how='inner')"
      ],
      "metadata": {
        "id": "U1g2a68mXmel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "tFJljXVhXwfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirm the Testing Set length \n",
        "test_length = data[(data.index >= '2020-09-01')].shape[0]"
      ],
      "metadata": {
        "id": "ORgUW1yrX0qg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CreateFeatures_and_Targets(data, feature_length):\n",
        "    X = []\n",
        "    Y = []\n",
        "\n",
        "    for i in tnrange(len(data) - feature_length): \n",
        "        X.append(data.iloc[i : i + feature_length,:].values)\n",
        "        Y.append(data[\"Close\"].values[i+feature_length])\n",
        "\n",
        "    X = np.array(X)\n",
        "    Y = np.array(Y)\n",
        "\n",
        "    return X , Y"
      ],
      "metadata": {
        "id": "jBJiwygbX8WC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X , Y = CreateFeatures_and_Targets(data , 32)"
      ],
      "metadata": {
        "id": "ycjO1LYbYBgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def PredictStockPrice(Model , DataFrame , PreviousDate , feature_length = 32):\n",
        "    idx_location = DataFrame.index.get_loc(PreviousDate)\n",
        "    Features = DataFrame.iloc[idx_location - feature_length : idx_location,:].values\n",
        "    Features = np.expand_dims(Features , axis = 0)\n",
        "    Features = Feature_Scaler.transform(Features)\n",
        "    Prediction = Model.predict(Features)\n",
        "    Prediction = Target_Scaler.inverse_transform(Prediction)\n",
        "    return Prediction[0][0]"
      ],
      "metadata": {
        "id": "FpLnMCW3YgP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PredictStockPrice(loaded_model , data , '2021-01-14')"
      ],
      "metadata": {
        "id": "WGuhSKBCYhfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nCMD9b54YmBo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}